from PymoNNto import *
import tensorflow as tf
import time

class Basic_Behaviour_Tensorflow(Behaviour):

    def set_variables(self, neurons):
        neurons.voltage = tf.Variable(neurons.get_neuron_vec(), dtype='float32')
        neurons.spike = tf.Variable(neurons.get_neuron_vec(), dtype='float32')
        self.threshold = tf.constant(0.5, dtype='float32')
        self.decay_factor = tf.constant(0.9, dtype='float32')

    def new_iteration(self, neurons):
        firing = tf.greater(neurons.voltage, self.threshold)
        neurons.spike.assign(tf.cast(firing, dtype='float32'))#spikes

        not_firing = tf.cast(tf.math.logical_not(firing), dtype='float32')#reset
        neurons.voltage.assign(tf.multiply(neurons.voltage, not_firing))

        new_voltage = tf.multiply(neurons.voltage, self.decay_factor)#voltage decay
        rnd_act = tf.constant(neurons.get_neuron_vec('uniform', density=0.01), dtype='float32')
        neurons.voltage.assign(tf.add(new_voltage, rnd_act)) #noise


class Input_Behaviour_Tensorflow(Behaviour):

    def set_variables(self, neurons):
        for syn in neurons.afferent_synapses['GLUTAMATE']:
            syn.W = tf.Variable(syn.get_synapse_mat('uniform', density=0.1), dtype='float32')

    def new_iteration(self, neurons):
        for synapse in neurons.afferent_synapses['GLUTAMATE']:
            W_act_mul = tf.linalg.matvec(synapse.W, synapse.src.spike)
            delta_act = tf.divide(W_act_mul, synapse.src.size/10.0)
            neurons.voltage.assign(tf.add(neurons.voltage, delta_act))




class Basic_Behaviour(Behaviour):
    '''
    def set_variables(self, neurons):
        neurons.voltage = neurons.get_neuron_vec()
        self.threshold = 0.5
        self.leak_factor = self.get_init_attr('leak_factor', 0.9, neurons)

    def new_iteration(self, neurons):
        firing = neurons.voltage > self.threshold
        neurons.spike = firing.astype(def_dtype) #spikes
        neurons.voltage[firing] = 0.0 #reset

        neurons.voltage *= self.leak_factor #voltage decay
        neurons.voltage += neurons.get_neuron_vec('uniform',density=0.01) #noise
    '''

class Input_Behaviour(Behaviour):
    '''
    def set_variables(self, neurons):
        for synapse in neurons.afferent_synapses['GLUTAMATE']:
            synapse.W = synapse.get_synapse_mat('uniform', density=0.1)
            #synapse.enabled = synapse.W > 0

    def new_iteration(self, neurons):
        for synapse in neurons.afferent_synapses['GLUTAMATE']:
            neurons.voltage += synapse.W.dot(synapse.src.spike)/synapse.src.size*10
    '''

measurements_np = []

for N_e in [100 * (i + 1) for i in range(100)]:

    My_Network = Network()

    My_Neurons = NeuronGroup(net=My_Network, tag='my_neurons', size=get_squared_dim(N_e), behaviour={
        1: Basic_Behaviour(),
        #2: Input_Behaviour(),
        # 9: Recorder(tag='my_recorder', variables=['n.voltage', 'np.mean(n.voltage)']),
        # 10: EventRecorder(tag='my_event_recorder', variables=['n.spike'])
    })

    #My_Neurons.visualize_module()

    my_syn = SynapseGroup(net=My_Network, src=My_Neurons, dst=My_Neurons, tag='GLUTAMATE')

    My_Network.initialize()

    start = time.time()

    My_Network.simulate_iterations(1000, measure_block_time=True)

    measure = time.time() - start
    print('np', N_e, measure)
    measurements_np.append(measure)

print(measurements_np)


measurements_tf = []

for N_e in [100*(i+1) for i in range(100)]:

    My_Network = Network()

    My_Neurons = NeuronGroup(net=My_Network, tag='my_neurons', size=get_squared_dim(N_e), behaviour={
        1: Basic_Behaviour_Tensorflow(),
        2: Input_Behaviour_Tensorflow(),
        #9: Recorder(tag='my_recorder', variables=['n.voltage.numpy()', 'np.mean(n.voltage.numpy())'])
    })

    my_syn = SynapseGroup(net=My_Network, src=My_Neurons, dst=My_Neurons, tag='GLUTAMATE')

    My_Network.initialize()

    start = time.time()

    My_Network.simulate_iterations(1000, measure_block_time=True)

    measure=time.time()-start
    print('tf', N_e, measure)
    measurements_tf.append(measure)

print(measurements_tf)

import matplotlib.pyplot as plt

plt.plot([100*(i+1) for i in range(100)], measurements_np, label='numpy')
plt.plot([100*(i+1) for i in range(100)], measurements_tf, label='tensorflow')

plt.legend()

plt.xlabel('number of neurons')
plt.ylabel('seconds')

plt.show()

#[0.1999645233154297, 0.218003511428833, 0.2409965991973877, 0.24100112915039062, 0.24899935722351074, 0.2630031108856201, 0.28099799156188965, 0.31284523010253906, 0.32000279426574707, 0.35899925231933594, 0.4546220302581787, 0.5068552494049072, 0.6530053615570068, 0.7824952602386475, 0.9070553779602051, 1.050222396850586, 1.2891442775726318, 1.66923189163208, 1.60029935836792, 1.7296044826507568, 1.9204566478729248, 2.1690399646759033, 2.4417033195495605, 2.7384917736053467, 2.996511459350586, 3.2402493953704834, 3.5744411945343018, 3.7405831813812256, 4.142074346542358, 4.389730215072632, 4.720706224441528, 5.068341493606567, 5.323216199874878, 5.427221298217773, 6.041033029556274, 6.1748316287994385, 6.64346718788147, 7.3407182693481445, 7.764008522033691, 8.06881833076477, 8.047604084014893, 9.072882175445557, 9.604224681854248, 10.077693939208984, 10.647050619125366, 10.811450481414795, 10.993111848831177, 12.000470161437988, 12.116547346115112, 12.536857843399048, 12.88845944404602, 13.422639846801758, 14.475027561187744, 14.691237211227417, 15.31989574432373, 15.789008378982544, 15.725893020629883, 16.90374231338501, 17.846120834350586, 17.899065256118774, 19.737046718597412, 20.413366317749023, 20.703333616256714, 21.389984607696533, 22.651919841766357, 23.285500049591064, 24.05386972427368, 23.718878746032715, 23.88205051422119, 25.99735450744629, 26.330946683883667, 27.611251831054688, 25.931657075881958, 28.251221418380737, 29.352930784225464, 30.91769289970398, 31.067970752716064, 31.953543424606323, 33.25282263755798, 34.06226468086243, 34.59615874290466, 34.87780523300171, 36.2314133644104, 37.31342148780823, 38.83990836143494, 39.85849905014038, 39.83023977279663, 41.045506954193115, 41.741124391555786, 42.58165979385376, 36.91175675392151, 45.72424578666687, 46.39647197723389, 48.61268162727356, 48.692301988601685, 48.81277871131897, 47.00536918640137, 51.17316174507141, 52.45090198516846, 52.031840801239014]

#[7.5436859130859375, 0.952052116394043, 0.9580111503601074, 0.9685888290405273, 0.9637916088104248, 0.9609682559967041, 0.9582045078277588, 0.9666166305541992, 0.9602880477905273, 0.9593665599822998, 0.96071457862854, 0.9613845348358154, 0.9573400020599365, 0.9606430530548096, 0.957266092300415, 1.0250699520111084, 1.111067771911621, 1.1128811836242676, 1.112034797668457, 1.1252353191375732, 1.1131031513214111, 1.1081557273864746, 1.1075670719146729, 1.1076288223266602, 1.115097999572754, 1.112248420715332, 1.1637375354766846, 1.6383483409881592, 1.3756556510925293, 1.1744801998138428, 1.375967025756836, 1.275254487991333, 1.2132048606872559, 1.3637316226959229, 1.167999029159546, 1.110478162765503, 1.1121060848236084, 1.1140496730804443, 1.1111562252044678, 1.1099636554718018, 1.1093626022338867, 1.1175684928894043, 1.1157429218292236, 1.1157095432281494, 1.108757734298706, 1.1133456230163574, 1.1231358051300049, 1.1213793754577637, 1.1171722412109375, 1.1200764179229736, 1.2808949947357178, 1.113271951675415, 1.1118769645690918, 1.1159610748291016, 1.1039340496063232, 1.1137936115264893, 1.1079671382904053, 1.1162211894989014, 1.1065483093261719, 1.1100184917449951, 1.109309196472168, 1.115638256072998, 1.1088998317718506, 1.1106536388397217, 1.1103167533874512, 1.1180434226989746, 1.1076114177703857, 1.1195812225341797, 1.1154916286468506, 1.1275899410247803, 1.1083252429962158, 1.1417183876037598, 1.2657194137573242, 1.114706039428711, 1.110335111618042, 1.1145620346069336, 1.1165761947631836, 1.115522861480713, 1.1208722591400146, 1.1202313899993896, 1.1110260486602783, 1.1216835975646973, 1.118427038192749, 1.11830735206604, 1.11627197265625, 1.16538405418396, 1.1439399719238281, 1.1223349571228027, 1.1150081157684326, 1.116992712020874, 1.1149985790252686, 1.1209912300109863, 1.1163032054901123, 1.1139283180236816, 1.1196205615997314, 1.1200335025787354, 1.1184258460998535, 1.1198973655700684, 1.1210017204284668, 1.1307590007781982]
#[1.0375339984893799, 0.846888542175293, 0.8502368927001953, 0.874018669128418, 0.8646717071533203, 0.8777210712432861, 0.8826766014099121, 0.8949623107910156, 0.9039154052734375, 0.8959107398986816, 0.9153125286102295, 1.0273284912109375, 1.0967259407043457, 1.125180959701538, 1.1337387561798096, 1.282701015472412, 1.490036964416504, 1.2799286842346191, 1.4653677940368652, 1.2617661952972412, 1.5102744102478027, 1.433044672012329, 1.4594035148620605, 1.5002355575561523, 1.7913098335266113, 1.4519846439361572, 1.5072216987609863, 1.6268677711486816, 1.7098968029022217, 1.7852282524108887, 1.569800615310669, 1.592090368270874, 1.6580989360809326, 1.6143760681152344, 1.7648184299468994, 1.7046303749084473, 1.7859089374542236, 1.8046839237213135, 1.928462266921997, 1.998405933380127, 2.577794075012207, 2.218118667602539, 2.2270667552948, 2.478893280029297, 2.0960397720336914, 2.0741958618164062, 2.119929790496826, 2.2006101608276367, 2.368408441543579, 2.5351409912109375, 2.348578691482544, 2.535757303237915, 2.472599744796753, 2.5393736362457275, 3.3418073654174805, 2.674172878265381, 2.703228235244751, 2.778975009918213, 3.4673781394958496, 3.00382661819458, 3.040437698364258, 3.065504550933838, 3.147279739379883, 3.2131474018096924, 3.3391878604888916, 3.35221791267395, 3.3938090801239014, 3.60068941116333, 3.6466681957244873, 3.620664596557617, 3.6706175804138184, 3.6609838008880615, 3.7540321350097656, 3.850482225418091, 3.9147279262542725, 3.9719412326812744, 4.121798753738403, 4.182462453842163, 4.401285886764526, 4.502908945083618, 4.515851974487305, 4.420205116271973, 4.755411148071289, 4.661699295043945, 4.690902471542358, 4.761011600494385, 4.905830144882202, 4.967146873474121, 5.132516860961914, 5.1854941844940186, 5.16105580329895, 5.211744785308838, 5.413797855377197, 5.468248128890991, 5.737350702285767, 6.1713035106658936, 5.800194025039673, 5.879356384277344, 6.048494100570679, 5.962701082229614]
